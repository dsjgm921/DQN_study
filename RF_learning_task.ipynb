{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Reinforcement Learning"
      ],
      "metadata": {
        "id": "8q_t0zT22Bo1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### install required pacakges for RF in colab"
      ],
      "metadata": {
        "id": "J0VunHD7xNIW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EGUYLlyxEQR",
        "outputId": "a25a6325-cc08-4c30-fda0-a50ec92b68e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym[classic_control] in /usr/local/lib/python3.8/dist-packages (0.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from gym[classic_control]) (1.5.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.8/dist-packages (from gym[classic_control]) (5.1.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.8/dist-packages (from gym[classic_control]) (1.21.6)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from gym[classic_control]) (0.0.8)\n",
            "Collecting pygame==2.1.0\n",
            "  Downloading pygame-2.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 18.3 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.8.0->gym[classic_control]) (3.11.0)\n",
            "Installing collected packages: pygame\n",
            "Successfully installed pygame-2.1.0\n"
          ]
        }
      ],
      "source": [
        "pip install gym[classic_control]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RF_ import modules and basic configurations"
      ],
      "metadata": {
        "id": "ecMeopeOxZbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# gym library for reinforcement learning\n",
        "import gym\n",
        "\n",
        "# math and random library for math modules and random numbers \n",
        "import math\n",
        "import random\n",
        "\n",
        "# numpy library \n",
        "import numpy as np\n",
        "\n",
        "# matplotlib for visualization \n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# collections library for data structures \n",
        "from collections import namedtuple, deque\n",
        "\n",
        "from itertools import count\n",
        "\n",
        "# torch library \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "s3VIFu_exE-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# specified certain version of gym library\n",
        "# and exceptions \n",
        "\n",
        "if gym.__version__[:4] == '0.26':\n",
        "    env = gym.make('CartPole-v1')\n",
        "elif gym.__version__[:4] == '0.25':\n",
        "    env = gym.make('CartPole-v1', new_step_api=True)\n",
        "else:\n",
        "    raise ImportError(f\"Requires gym v25 or v26, actual version: {gym.__version__}\")\n",
        "\n",
        "# If one's environment is jupyter or collab , the code and the return is as follows  \n",
        "# \" is_ipython = True \"\n",
        "#\n",
        "\n",
        "# set up matplotlib inline function \n",
        "# you can display images inside jupyter / colab , below code\n",
        "is_ipython = 'inline' in matplotlib.get_backend()\n",
        "\n",
        "# When you enable the ‘inline’ matplotlib backend, \n",
        "# the output of the plotting commands written will be displayed inline within the frontends like jupyter notebook. \n",
        "# It means, the plot/graph will be displayed directly below the cell (where the plotting commands are written) \n",
        "# and the resulted plot/graph will also be included (stored) in your notebook document.\n",
        "\n",
        "if is_ipython:\n",
        "    from IPython import display\n",
        "\n",
        "# an example on how to use IPython display  \n",
        "# from IPython.display import Image\n",
        "# Image(filename='test.png') \n",
        "\n",
        "#the function to turn on interactive mode ( I.nteractivemode O.N.  = ion )\n",
        "plt.ion()\n",
        "\n",
        "# if gpu is to be used\n",
        "# set device to cuda , and accelerate if cuda is available \n",
        "# else, set train device to cpu \n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "kSvTOZzxzxnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How to make nametuple identity \n",
        "\n",
        "from collections import namedtuple\n",
        "\n",
        "# namedtuple_structure_name as variable = namedtuple(tuplename,[tuple1,tuple2,tuple3,tuple4]) \n",
        "Employee = namedtuple('Employee',['first_name', 'last_name', 'country', 'jobs'])\n",
        "\n",
        "# identity_name = namedtuple_structure_name(tuple1,tuple2,tuple3,tuple4)\n",
        "andrew = Employee('Andrew', 'Brown', 'US', ['Developer', 'Manager'])\n",
        "\n",
        "print(andrew)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYE6ANb63GMX",
        "outputId": "0b16477c-927c-4cf3-ff1b-a78c9d019651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Employee(first_name='Andrew', last_name='Brown', country='US', jobs=['Developer', 'Manager'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# namedtuple example \n",
        "\n",
        "hoji = Employee('Hoji','Kim',\"KR\",['Developer'])\n",
        "print(hoji)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNG5FeDy3HaD",
        "outputId": "334de3f9-5853-47e1-ae0c-9ef7f3424e20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Employee(first_name='Hoji', last_name='Kim', country='KR', jobs=['Developer'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# how to use namedtuple? \n",
        "# feable examples\n",
        "\n",
        "print(f'first_name by index[0]\\t: {hoji[0]}') \n",
        "print(f'last_name by index[1]\\t: {hoji[1]}') \n",
        "print(f'country by index[2]\\t: {hoji[2]} \\n') \n",
        "\n",
        "print(f'first_name by attribute\\t:{hoji.first_name}') \n",
        "print(f'last_name by attribute\\t:{hoji.last_name}') \n",
        "print(f'jobs by attribute\\t:{hoji.jobs}') \n",
        "\n",
        "#Employee(*args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cjxCyzb3pbE",
        "outputId": "af88dae0-f4d1-44c7-90da-1dad3870a87d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first_name by index[0]\t: Hoji\n",
            "last_name by index[1]\t: Kim\n",
            "country by index[2]\t: KR \n",
            "\n",
            "first_name by attribute\t:Hoji\n",
            "last_name by attribute\t:Kim\n",
            "jobs by attribute\t:['Developer']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transition - a named tuple representing a single transition in our environment. \n",
        "# It essentially maps (state, action) pairs to their (next_state, reward) result, \n",
        "# with the state being the screen difference image as described later on.\n",
        "\n",
        "# In Python, most people don’t know — or usually forget about — \n",
        "# is that the language comes with an extension type called Named Tuple that is built on top of the core tuple type.\n",
        "\n",
        "# So, what is namedtuple?\n",
        "# can use indexes and attribute for lookup ( dic + list ?? )\n",
        "# “factory function for creating tuple subclasses with named fields“ — Python docs\n",
        "\n",
        "Transition = namedtuple('Transition',\n",
        "                        ('state', 'action', 'next_state', 'reward'))\n",
        "\n",
        "\n",
        "# what is replaymemory \n",
        "# ReplayMemory - a cyclic buffer of bounded size that holds the transitions observed recently. \n",
        "# 일정한 크기의 제한된 순환식 버퍼를 가지고 트랜지션 정보를 최신순으로 계속 받고 내보내는 일종의 데크 구조?라고 보면 되나 \n",
        "\n",
        "# It also implements a .sample() method for selecting a random batch of transitions for training.\n",
        "# 가지고 있는 버퍼에서 랜덤 배치로 자료를 선택하여 트레이닝도 가능하다. \n",
        "\n",
        "# 리플레이 메모리는 object를 부모클래스로 상속받은 자식클래스 \n",
        "# 리플레이메모리(오브젝트)\n",
        "# 자식클래스(부모클래스)\n",
        "\n",
        "# what is object class in python\n",
        "# 파이썬 3 코드에서 굳이 object를 상속시켜 주는 이유는 대개 파이썬 2와의 호환성 혹은 작성 취향 때문이다.\n",
        "# 레퍼런스 : https://jh-bk.tistory.com/24\n",
        "# 파이썬 3에선 old-style class를 만들 수 있는 방법은 공식적으론 없으며, 모든 클래스는 object를 상속받는 new-style class라고 보면 된다.\n",
        "\n",
        "# 따라서 class ReplayMemory(object) == class ReplayMemory() ?? seems like it \n",
        "\n",
        "class ReplayMemory(object):\n",
        "    \n",
        "    # initialization function \n",
        "    def __init__(self, capacity):\n",
        "        self.memory = deque([],maxlen=capacity)\n",
        "    \n",
        "    # memory.push(state, action, next_state, reward)\n",
        "    # usage is like this ---> push(Transition(\"*args -> state,action,next_state,reward\")) \n",
        "    def push(self, *args):\n",
        "        \"\"\"Save a transition\"\"\"\n",
        "        self.memory.append(Transition(*args))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "    \n",
        "    # what is def__len__()???? \n",
        "\n",
        "    # when we call len(s) method, s.__len__() is what actually happening behind the scenes to calculate the length.\n",
        "    # def len(s):\n",
        "    # return s.__len__()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)"
      ],
      "metadata": {
        "id": "c4ziV_qZxGL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inherits torch nn.Module \n",
        "# Deep Q Network \n",
        "\n",
        "\n",
        "class DQN(nn.Module):\n",
        "    # DQN은 initialized 될 때 DQN(n_obs,n_actions) 으로 동작한다 \n",
        "\n",
        "    def __init__(self, n_observations, n_actions):\n",
        "        \n",
        "        # super().__init__() → python 3 에서만 작동\n",
        "        # super(클래스,self).__init__() → python 2,3 모두 작동\n",
        "        # DQN 에서 nn.Module 의 함수들을 사용하겠다\n",
        "\n",
        "        super(DQN, self).__init__()\n",
        "\n",
        "        # DQN의 layer1,2,3  \n",
        "        self.layer1 = nn.Linear(n_observations, 128)\n",
        "        self.layer2 = nn.Linear(128, 128)\n",
        "        self.layer3 = nn.Linear(128, n_actions)\n",
        "\n",
        "    # Called with either one element to determine next action, or a batch\n",
        "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
        "    \n",
        "    # 일반적인 연결구조 \n",
        "    # One element를 return 하면 다음에 취할 액션이 리턴될 것 \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.layer1(x))\n",
        "        x = F.relu(self.layer2(x))\n",
        "        return self.layer3(x)"
      ],
      "metadata": {
        "id": "vjhzCGDXxz32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Deterministic Environment \n",
        "\n",
        "# Q - Learning Idea\n",
        "# The main idea behind Q-learning is that \n",
        "# if we had a function Q*: State X Action -> R \n",
        "# that could tell us what our return would be, \n",
        "\n",
        "# 함수 Q(상태,행동)가 있다면 어떤 상태에서 특정 행동을 취함으로써 얻는 보상을 알 수 있다.\n",
        "# 주어진 상황에서 행동을 취한다고 가정하면 보상을 극대화 하는 폴리시를 쉽게 구성할 수 있다.\n",
        "\n",
        "# DQN - Learning Idea \n",
        "# given Q(s,a) -> R를 모르니, 뉴럴 네트워크로 근사(Resemble)한다 \n",
        "\n",
        "\n",
        "# BATCH_SIZE is the number of transitions sampled from the replay buffer\n",
        "# works like this \n",
        "# memory = ReplayMemory(10000)\n",
        "# transitions = memory.sample(BATCH_SIZE)\n",
        "\n",
        "# 리플레이 메모리 클래스를 할당받은 메모리에서 128만큼 배치 사이즈를 랜덤으로 샘플링하겠다 \n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# GAMMA is the discount factor as mentioned in the previous section\n",
        "# constant between 0 ~ 1 -> sum must be converged\n",
        "GAMMA = 0.99\n",
        "\n",
        "# policy(S) = argmax(current State, action)\n",
        "# 현 상태에서 어떤 액션을 취했을때 가장 높은 Q-value를 리턴하는 폴리시\n",
        "\n",
        "# every Q function for some policy obeys the Bellman equation:\n",
        "# Q(policy(state,action)) = { return + gamma(Q(policy(next state, policy(next state))) }\n",
        "# temporal difference error = Q(policy(state,action)) - { return + gamma(Q(policy(next state, policy(next state))) }\n",
        "# uses Huber loss \n",
        "\n",
        "\n",
        "# Epsilon parameter\n",
        "# Uses Epsilon greedy policy \n",
        "# controls the rate of the decay (higher = slower decay )\n",
        "EPS_DECAY = 1000\n",
        "\n",
        "# Epsilon start value , 0.9 \n",
        "EPS_START = 0.9\n",
        "# Epsilon end value , 0.05 \n",
        "# 0.9 -> exp_decay towards -> 0.05 \n",
        "EPS_END = 0.05\n",
        "\n",
        "# TAU is the update rate of the target network\n",
        "TAU = 0.005\n",
        "\n",
        "# LR is the learning rate of the AdamW optimizer\n",
        "LR = 1e-4\n",
        "\n",
        "# Get number of actions from gym action space\n",
        "# print(\"n_actions\", n_actions) -> 2 \n",
        "# Q(s,left) or Q(s,right)\n",
        "n_actions = env.action_space.n\n",
        "# print(\"n_actions\", n_actions)\n",
        "\n",
        "# Get the number of state observations\n",
        "if gym.__version__[:4] == '0.26':\n",
        "    state, _ = env.reset()\n",
        "elif gym.__version__[:4] == '0.25':\n",
        "    state, _ = env.reset(return_info=True)\n",
        "\n",
        "# n_observations = 4 \n",
        "# DQN에서는 기본적으로 4개의 연속된 observation들이 들어감으로서 \n",
        "# 상황의 흐름을 train 할 수 있다 \n",
        "n_observations = len(state)\n",
        "# print(\"n_observations :\",len(state))\n",
        "\n",
        "policy_net = DQN(n_observations, n_actions).to(device)\n",
        "target_net = DQN(n_observations, n_actions).to(device)\n",
        "\n",
        "# nn.Module.load_state_dict() \n",
        "# print(\"state_dict\" ,policy_net.state_dict())\n",
        "# loads weight * bias for each layer \n",
        "# 폴리시 넷 ( 타우에 따라 늦게 업데이트 된 )의 가중치와 편향을 타겟 넷에 적재하는 과정 \n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "# amsgrad = auto \n",
        "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
        "\n",
        "memory = ReplayMemory(10000)\n",
        "\n",
        "steps_done = 0\n",
        "\n",
        "def select_action(state):\n",
        "    # steps_done 을 전역 변수로 설정 \n",
        "    global steps_done\n",
        "    \n",
        "    # 난수생성\n",
        "    sample = random.random()\n",
        "    \n",
        "    # epsilon을 매 스텝이 진행됨에 따라 지수적으로 증가해주는 구간 \n",
        "    # exp(0) = 1\n",
        "    # 0에 가까워질 수록 1에 수렴하는 지수함수 \n",
        "\n",
        "    # 0.05 + ( 0.85 ) * exp(-1 * 1/1000 ) -> 거의 0.05 + 0.85 \n",
        "    # 0.05 + ( 0.85 ) * exp(-1 * 1/2 ) -> 거의 0.05 + 0.085 * (0.7)\n",
        "    # 0.05 + ( 0.85 ) * exp(-1 * 1/1 ) -> 거의 0.05 + 0.85 * (0.6)\n",
        "    # 즉 STEPS DONE이 진행될수록 EPSILON이 DECAY 되게끔 작성된 코드다 \n",
        "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
        "        math.exp(-1. * steps_done / EPS_DECAY)\n",
        "    \n",
        "    steps_done += 1\n",
        "    \n",
        "    # 만약 생성한 난수가 허용치보다 높은 경우에는 \n",
        "    # Q.argmax(state)로 액션을 정한다 \n",
        "\n",
        "    # torch.no_grad()의 주된 목적은 autograd를 끔으로써 메모리 사용량을 줄이고 연산 속도를 높히기 위함\n",
        "    # 이 컨텍스트 내부에서 새로 생성된 텐서들은 requires_grad=False 상태가 되어, 메모리 사용량을 아껴준다.\n",
        "    \n",
        "    # 만약 생성한 난수가 허용치보다 낮은 경우에는 \n",
        "    # 무작위로 액션을 설정한다 \n",
        "    \n",
        "    if sample > eps_threshold:\n",
        "        with torch.no_grad():\n",
        "            # t.max(1) will return largest column value of each row.\n",
        "            # second column on max result is index of where max element was\n",
        "            # found, so we pick action with the larger expected reward.\n",
        "            return policy_net(state).max(1)[1].view(1, 1)\n",
        "    else:\n",
        "        return torch.tensor([[env.action_space.sample()]], device=device, dtype=torch.long)\n",
        "\n",
        "\n",
        "episode_durations = []\n",
        "\n",
        "\n",
        "# plot_durations for plotting \n",
        "def plot_durations(show_result=False):\n",
        "    \n",
        "    plt.figure(1)\n",
        "\n",
        "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
        "    \n",
        "    if show_result:\n",
        "        plt.title('Result')\n",
        "    else:\n",
        "        plt.clf()\n",
        "        plt.title('Training...')\n",
        "    \n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Duration')\n",
        "    plt.plot(durations_t.numpy())\n",
        "\n",
        "    # Take 100 episode averages and plot them too\n",
        "    if len(durations_t) >= 100:\n",
        "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
        "        means = torch.cat((torch.zeros(99), means))\n",
        "        plt.plot(means.numpy())\n",
        "\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "    \n",
        "    if is_ipython:\n",
        "        if not show_result:\n",
        "            display.display(plt.gcf())\n",
        "            display.clear_output(wait=True)\n",
        "        else:\n",
        "            display.display(plt.gcf())"
      ],
      "metadata": {
        "id": "R-YciovIx4yf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize_model():\n",
        "    if len(memory) < BATCH_SIZE:\n",
        "        return\n",
        "\n",
        "    transitions = memory.sample(BATCH_SIZE)\n",
        "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
        "    # detailed explanation). This converts batch-array of Transitions\n",
        "    # to Transition of batch-arrays.\n",
        "    batch = Transition(*zip(*transitions))\n",
        "\n",
        "    # Compute a mask of non-final states and concatenate the batch elements\n",
        "    # (a final state would've been the one after which simulation ended)\n",
        "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
        "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
        "    non_final_next_states = torch.cat([s for s in batch.next_state if s is not None])\n",
        "    state_batch = torch.cat(batch.state)\n",
        "    action_batch = torch.cat(batch.action)\n",
        "    reward_batch = torch.cat(batch.reward)\n",
        "\n",
        "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
        "    # columns of actions taken. These are the actions which would've been taken\n",
        "    # for each batch state according to policy_net\n",
        "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
        "\n",
        "    # Compute V(s_{t+1}) for all next states.\n",
        "    # Expected values of actions for non_final_next_states are computed based\n",
        "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
        "    # This is merged based on the mask, such that we'll have either the expected\n",
        "    # state value or 0 in case the state was final.\n",
        "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
        "    with torch.no_grad():\n",
        "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0]\n",
        "    # Compute the expected Q values\n",
        "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
        "\n",
        "    # Compute Huber loss\n",
        "    criterion = nn.SmoothL1Loss()\n",
        "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
        "\n",
        "    # Optimize the model\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    # In-place gradient clipping\n",
        "    torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "jNX5RrsKx65T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1o-JXUxyTu9",
        "outputId": "e767f640-84c0-475a-f1e1-f04bf9d4824a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set num_epsides ~ GPU availability\n",
        "if torch.cuda.is_available():\n",
        "    num_episodes = 600\n",
        "else:\n",
        "    num_episodes = 300\n",
        "\n",
        "# episode tranining \n",
        "for i_episode in range(num_episodes):\n",
        "    # Initialize the environment and get it's state\n",
        "    \n",
        "    # gym.__version__ 0.26 returns info without any args\n",
        "    if gym.__version__[:4] == '0.26':\n",
        "        state, _ = env.reset()\n",
        "    # gym.__version__ 0.25 args must be set True to return_info\n",
        "    elif gym.__version__[:4] == '0.25':\n",
        "        state, _ = env.reset(return_info=True)\n",
        "    # env.reset resets the state of the env and returns an initial obs.\n",
        "    # 매 에피소드가 끝나면 env state를 초기화 해줌 \n",
        "    \n",
        "    # 매번 초기화 되는 state \n",
        "    state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
        "    # print(state)\n",
        "    # tensor([[0.0092, 0.0344, 0.0363, 0.0075]])\n",
        "     \n",
        "    # counts() counts each loop \n",
        "    # t -> 1 -> 2 -> 3.... end \n",
        "\n",
        "    for t in count():    \n",
        "        # takes action ( from current state )\n",
        "        action = select_action(state)\n",
        "        \n",
        "        # In the old opengym API \n",
        "        # done was returned as True if episode ends in any way.\n",
        "        # In the new API, done is split into 2 parts: terminated -> truncated \n",
        "\n",
        "        observation, reward, terminated, truncated, _ = env.step(action.item())\n",
        "        \n",
        "        # moves reward to device( cuda or cpu )\n",
        "        reward = torch.tensor([reward], device=device)\n",
        "        \n",
        "        # one loop finished anyway \n",
        "        done = terminated or truncated\n",
        "        \n",
        "        # If terminated is returned as True , there is no next_state ... so, \n",
        "        if terminated:\n",
        "            next_state = None\n",
        "        # If terminated is returned as False, next_state exists ... so, \n",
        "        # next_state가 다음과 같이 선언된다. \n",
        "        # next_state의 인풋 역시 , DQN 처음 인풋대로 4개의 STATE가 들어간다 \n",
        "        else:\n",
        "            # print(observation,\"observation\")\n",
        "            # [-0.04615159  0.23102479 -0.03562462 -0.30272973] observation\n",
        "            \n",
        "            next_state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
        "\n",
        "        # Store the transition in memory\n",
        "        # push(args) into namedtuple Transition \n",
        "        memory.push(state, action, next_state, reward)\n",
        "\n",
        "        # Move to the next state\n",
        "        state = next_state\n",
        "\n",
        "        # Perform one step of the optimization (on the policy network)\n",
        "        optimize_model()\n",
        "\n",
        "        # Soft update of the target network's weights\n",
        "        # θ′ ← τ θ + (1 −τ )θ′\n",
        "        target_net_state_dict = target_net.state_dict()\n",
        "        policy_net_state_dict = policy_net.state_dict()\n",
        "        \n",
        "        # 같은 키에 해당되는 텐서들을 계산해줌 \n",
        "        for key in policy_net_state_dict:\n",
        "            target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
        "        \n",
        "        # 계산한 텐서들을 타겟 넷에 적재해줌 \n",
        "        target_net.load_state_dict(target_net_state_dict)\n",
        "        \n",
        "        # if terminated or truncated is true \n",
        "        # epsiode 한개는 끝났다고 생각해서 그만큼 진행을 해줌 ( 플롯을 위해서 )\n",
        "        if done:\n",
        "            episode_durations.append(t + 1)\n",
        "\n",
        "            # plot_durations() -> show_result -> False ( default )\n",
        "            plot_durations()\n",
        "            break\n",
        "\n",
        "print('Complete')\n",
        "\n",
        "# plot_durations() -> show_result false --> True ( shows result )\n",
        "plot_durations(show_result=True)\n",
        "plt.ioff()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "nocdHXhpx8wG",
        "outputId": "294cbb2a-fa7c-43ed-ae30-84d70927c78f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complete\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SK_29-QKx-2u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}